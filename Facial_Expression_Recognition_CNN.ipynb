{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a693042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 14:26:48.604057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bebabea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a97ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c80eb71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "981\n"
     ]
    }
   ],
   "source": [
    "CK_PATH=\"CK_PLUS/CK+48\" \n",
    "CK_PATH= pathlib.Path(CK_PATH)\n",
    "image_count = len(list(CK_PATH.glob('*/*.png')))\n",
    "#print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffbca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger = list(CK_PATH.glob('anger/*'))\n",
    "contempt = list(CK_PATH.glob('contempt/*'))\n",
    "disgust = list(CK_PATH.glob('disgust/*'))\n",
    "fear = list(CK_PATH.glob('fear/*'))\n",
    "happy = list(CK_PATH.glob('happy/*'))\n",
    "sadness = list(CK_PATH.glob('sadness/*'))\n",
    "surprise = list(CK_PATH.glob('surprise/*'))\n",
    "#PIL.Image.open(str(happy[0]))\n",
    "#print image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "250f6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "img_height = 48\n",
    "img_width = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8ff15653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 981 files belonging to 7 classes.\n",
      "Using 834 files for training.\n",
      "Found 981 files belonging to 7 classes.\n",
      "Using 147 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "CK_PATH,\n",
    "validation_split=0.15,\n",
    "subset=\"training\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size)\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "CK_PATH,\n",
    "validation_split=0.15,\n",
    "subset=\"validation\",\n",
    "seed=123,\n",
    "image_size=(img_height, img_width),\n",
    "batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de3d2f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "class_no = len(class_names)\n",
    "print(class_no )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aca5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------Data Augmentation------------\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "150cce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(10, 10)) #first 9 image with class\\nfor images, labels in train_ds.take(1):\\n    for i in range(9):\\n        ax = plt.subplot(3, 3, i + 1)\\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\\n        plt.title(class_names[labels[i]])\\n        plt.axis(\"off\")\\n        \\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "plt.figure(figsize=(10, 10)) #first 9 image with class\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "43eb8cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 48, 48, 3)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    input_shape = image_batch.shape\n",
    "    label_shape = labels_batch.shape\n",
    "    print(input_shape)\n",
    "    #print(label_shape )\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "398ed178",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch = image_batch.reshape(input_shape[0], input_shape[1], input_shape[2], 3)\n",
    "image_batch = image_batch.astype('float32')\n",
    "image_batch = image_batch/ 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38da562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST PROPOSED MODEL\n",
    "#-------------------\n",
    "model = keras.Sequential()\n",
    "#model.add(tf.keras.layers.Rescaling(1./255))\n",
    "\n",
    "#--convolutional layer x3---\n",
    "model.add(tf.keras.layers.Conv2D(6, kernel_size=(3, 3), activation='relu', input_shape=(image_batch.shape[1], image_batch.shape[2], 3) ))#image_batch.shape\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(image_batch.shape[1], image_batch.shape[2], 3) ))#image_batch.shape\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(image_batch.shape[1], image_batch.shape[2], 3) ))#image_batch.shape\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#--Fully Connected Layers x2---\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(class_no, activation='softmax'))\n",
    "\n",
    "\n",
    "#-------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20237115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 46, 46, 6)         168       \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 46, 46, 6)        24        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 23, 23, 6)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 21, 21, 16)        880       \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 21, 21, 16)       64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 10, 10, 16)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 8, 8, 128)         18560     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 8, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 4, 4, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 547,575\n",
      "Trainable params: 546,763\n",
      "Non-trainable params: 812\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "79b5860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bbb33b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 1s 38ms/step - loss: 0.1685 - accuracy: 0.9496 - val_loss: 0.3461 - val_accuracy: 0.9456\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1876 - accuracy: 0.9424 - val_loss: 0.3301 - val_accuracy: 0.9456\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1976 - accuracy: 0.9329 - val_loss: 0.2526 - val_accuracy: 0.9456\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1386 - accuracy: 0.9532 - val_loss: 0.1943 - val_accuracy: 0.9660\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1437 - accuracy: 0.9508 - val_loss: 0.1997 - val_accuracy: 0.9592\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.1695 - accuracy: 0.9472 - val_loss: 0.1907 - val_accuracy: 0.9388\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1172 - accuracy: 0.9640 - val_loss: 0.1454 - val_accuracy: 0.9592\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 1s 30ms/step - loss: 0.0733 - accuracy: 0.9844 - val_loss: 0.1362 - val_accuracy: 0.9660\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 1s 29ms/step - loss: 0.1250 - accuracy: 0.9592 - val_loss: 0.1427 - val_accuracy: 0.9728\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 1s 31ms/step - loss: 0.1406 - accuracy: 0.9640 - val_loss: 0.1069 - val_accuracy: 0.9728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fba04611eb0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10,verbose=1,validation_data=test_ds)\n",
    "#validation_split=0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b37e34d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------DRAFT--------\n",
    "\n",
    "#normalization_layer = tf.keras.layers.Rescaling(1./255) # Normalize pixel values to be between 0 and 1\n",
    "\n",
    "#normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "#image_batch, labels_batch = next(iter(normalized_ds))\n",
    "\n",
    "\n",
    "#def relu(x): #ReLU Activation Function\n",
    " #   return(np.maximum(0, x))\n",
    "\n",
    "#ReLU_output=[]\n",
    "#for i in range(len(image_batch)):\n",
    "#    ReLU_output += [tf.keras.activations.relu(image_batch[i], max_value= max_val)] #testing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f517f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
